[{"title":"ansible中遇上的一个小问题","date":"2021-08-31T10:42:34.000Z","url":"/2021/08/31/ansibleproblem/","tags":[["故障处理","/tags/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/"],["ansible","/tags/ansible/"]],"categories":[["Linux","/categories/Linux/"]],"content":"今天在新工作的地方研究了一下自动化的playbook,刚好遇上一个很奇怪的问题,来自ansible(version=2.10.1) 问题描述由于需要利用ansible调用zabbix的JMX监控,而监控的触发器在不同环境又是不一样的，因此需要利用ansible的set_fact 模块,为不同的环境添加不同的模板。 同时ansible 需要支持自定义传参添加额外监控模板功能。以下是实现： 举个例子: 看起来很美好对吧 那就大错特错了。 实际执行起来这段playbook会被跳过 原因排查查来查去发现是因为加了with_item的原因, 由于item的默认值是一个空的列表inputParamZabbixTemplate: [] 实际上就不会对他进行操作。 解决办法解决办法其实比较简单，就是在这一步之前执行一个变量初始化操作，这样如果有item的话原有逻辑也能继续执行，同样的如果没有的话跳过，也能依照初始变量运行 "},{"title":"利用Earthly工具进行CI/CD","date":"2021-07-22T11:00:45.025Z","url":"/2021/07/22/earthly/","tags":[["DevOps","/tags/DevOps/"]],"categories":[["docker","/categories/docker/"]],"content":"Earthly工具尝试最近发现一个比较有意思的镜像构建工具Earthly,文档地址 根据Earthly工具的介绍,它相当于Dockerfile+MAkefile+Bash 简单部署根据官网文档简单试用一下： 因为各种原因，个人选择在docker:dind的容器环境中尝试使用。 启动docker:dind容器： 在容器中： 官网例子 Earthfile: hello.py: 执行build部分： 执行docker部分 Earthly + Gitlab-CI简单实践备注：此处仅做演示,故仅采用docker:dind容器来进行CI,仓库仍采用上面的python演示仓库 Earthfile .gitlab-ci.yml 等待执行完毕即可,生产环境清使用专有earthly镜像"},{"title":"在阿里云ack中部署Yapi","date":"2021-07-22T10:48:19.309Z","url":"/2021/07/22/yapi-ack/","tags":[["kubernetes","/tags/kubernetes/"],["DevOps","/tags/DevOps/"]],"categories":[["kubernetes","/categories/kubernetes/"]],"content":"昨天遇上的需求，需要在公网环境部署一个Yapi服务,用于接口测试。做个小记录。 参考了此处 构建Yapi镜像搜索之后发现Yapi官方并没有提供镜像,于是参考上面的文档自己制作了一个镜像,过程参考上面的文档即可。 部署mongodb这边为了方便,使用helm部署。 从helm仓库下载helm chart 修改参数这边修改了以下参数： 部署 建立Yapi账号和数据库直接进pod执行，也没啥好说的 安装Yapi我们刚才已经制作了一个Yapi的镜像，为了方便使用，将其推送到公网的的自建harbor上。 使用kustomize来部署 kustomization.yaml deployment.yaml secret.yaml service.yaml ingress.yaml 部署"},{"title":"从python脚本到skopeo 容器搬运篇(2)","date":"2021-07-21T10:39:29.874Z","url":"/2021/07/21/imagetrans/","tags":[["docker","/tags/docker/"]],"categories":[["docker","/categories/docker/"]],"content":"在生产中有时候会遇上一个比较恶心的问题，因为经常性需要去各个甲方部署，公司的平台基于docker-compose部署，另外还有大大小小各种乱七八糟几百个镜像的业务依赖，每部署一次都需要重新挑出所需的镜像对其进行导出，再将其部署。 原有方案将docker镜像通过docker save 的方式导出为tar包，然后再到需要部署的机器上导入： 问题这个方案存在两个问题，一来是docker容器通过docker save 导出后会占用大量的磁盘空间，而且费时费力，另外需要在某台机器先部署好镜像才能进行导出， 为了提高效率，拟采用新的方式进行镜像的搬运。 使用私有镜像仓库来进行搬运docker 官方镜像中存在docker registry的镜像，该镜像可比较方便的进行导入导出，并且镜像分层，可以较好的解决磁盘占用和导入时间长的问题。这个方式类似上一章中提到的harbor做镜像存储操作， 此时registry文件夹即保存的镜像， 部署： 通过python脚本简单下载： 问题这个方案虽然解决磁盘占用问题，但仍需要通过本地的docker 导出镜像。同样会带来大量的镜像。 最终方案(?)最近听说了skopeo之后发现它可以比较方便的解决这个问题，但执行起来还是有一些阻碍： 各种依赖镜像原本都是使用Dockerfile进行构建的,此时使用skopeo去获取镜像并不容易 skopeo保存的镜像仍然存在分层重复的问题，重复占用磁盘的问题仍旧存在。 解决问题： 参考了此处 搭建私有的harbor仓库不多做赘述,可以参考此处 在本地构建镜像后推送到私有harbor先构建全部的可能用到的镜像，构建过程略，在harbor建立一个image仓库，然后推送： 使用skopeo拉取镜像skopeo镜像拉取方式： 通过脚本获取需要的镜像列表，然后对其分别拉取到image目录。 此时image的目录结构如下： 转换拉取的镜像文件 导出后文件夹格式： 拉取镜像测试"},{"title":"从python脚本到skopeo 容器搬运篇(1)","date":"2021-07-19T13:53:33.395Z","url":"/2021/07/19/skopeo1/","tags":[["docker","/tags/docker/"]],"categories":[["docker","/categories/docker/"]],"content":"镜像搬运的必要性由于业务原因经常有要求对镜像分组管理的要求，但很多镜像原本是重复的,并且都是单独的镜像，无法以单独的compose或者其他形式管理，要跨机器搬运就比较困难，原有的做法是新建一个临时的harbor仓库，做一个中转。 原有的搬运操作原有的一些镜像是存储在单独的一台服务器上，以docker image形式存在的,所以只进行了打包和推送操作: 在另外一台机器上部署： skopeo的使用和操作安装参照此链接 进行安装 基本使用 登陆私有仓库 拷贝到仓库： "},{"title":"kubernetes学习笔记(tekton)---基本部署","date":"2021-07-01T16:25:07.775Z","url":"/2021/07/02/kubernetes%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(tekton)/","tags":[["kubernetes","/tags/kubernetes/"],["DevOps","/tags/DevOps/"],["tekton","/tags/tekton/"]],"categories":[["kubernetes","/categories/kubernetes/"]],"content":"简介Tekton是一个云原生的CI/CD构建框架。 基本概念Task: Tekton中最小的单位，一切任务都是由Task组成。 TaskRun：创建了一个TaskRun以后，每个TaskRun就会单独控制一个Pod，Task中的每一个Step都对应pod中的一个Container。 Pipeline： Pipeline由多个Task组成，多个Task串联，按顺序执行就组成了Pipeline。 PipelineRun ： PipelineRun的作用为实际执行Pipeline。 PipelineResource: PipelineResource是Pipeline上的各种输入输出资源，比如github上的源码(输入)，编译产物或者容器镜像(输出)。 ClusterTask: 是覆盖整个集群的任务，可以在集群的范围运行任务，而不是和Task一样只能在某一命名空间运行。 运行机制每当我们创建一个Pipeline，他就会读取其中的各个Task任务,执行PipelineRun时实际开始运行Pipeline，每次运行都会生成一个新的PipelineRun，它会产生对应的TaskRun,由TaskRun去产生对应的Pod，运行任务。 部署部署Tekton TekTon 国内可能存在镜像拉取失败问题，需要魔法方法解决。 部署Tekton的dashboard ，可以方便直观的管理Tekton 部署tkn工具tkn是Tekton的CLI工具，在github直接下载对应版本即可，使用tkn可以很方便的管理Tekton 基本部署就说这么多，下一节再研究基本使用"},{"title":"Docker连接harbor出现x509的处理办法","date":"2021-07-01T10:44:05.004Z","url":"/2021/07/01/Docker%E8%BF%9E%E6%8E%A5harbor%E5%87%BA%E7%8E%B0x509%E7%9A%84%E5%A4%84%E7%90%86%E5%8A%9E%E6%B3%95/","tags":[["docker","/tags/docker/"],["harbor","/tags/harbor/"],["Linux","/tags/Linux/"],["故障处理","/tags/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/"]],"categories":[["docker","/categories/docker/"]],"content":"今天在使用tekton做gitops时出现了x509的错误，kubernetes中的pod无法访问本地的harbor，出现这个问题的原因是本地的harbor用的是自签证书，导致docker访问时不信任。 原先的解决办法： 在/etc/docker/daemon.json添加 &quot;insecure-registries&quot;:[&quot;$DOMAIN/IP&quot;] ，然后重启docker。 但是由于不想关停测试用的kubernetes，这个办法就不可行了，于是采取了其他方式。 首先是将harbor的证书拷贝到/etc/pki/ca-trust/source/anchors/下 ，发现没有作用。 然后采取了如下方式。 在/etc/docker/certs.d(需要自建)新建一个文件夹 名称为harbor域名(e.g:www.example.com ),拷贝harbor的crt证书到此处。 成功运行tekton的task"},{"title":"定时任务(cron与at)","date":"2021-06-29T11:51:20.181Z","url":"/2021/06/29/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1(cron%E4%B8%8Eat)/","tags":[["Linux","/tags/Linux/"]],"categories":[["Linux","/categories/Linux/"]],"content":"cron(定时任务)cron是最常用的定时任务类型,用于执行周期性计划 对应的服务为crond，使用前请确保此服务已运行 常用命令crontab -e 使用vi文本编辑器编辑cronjob，可通过-u指定用户执行。 crontab -l 列出所有cronjob: crontab -r 删除用户的cronjob cronjob 格式 前五个*分别代表 分、时、日、月、周，最后一列是需要执行的命令。 使用L 可代表本月最后一天/本周最后一天： e.g: 在天（月）子表达式中，“L”表示一个月的最后一天在天（星期）自表达式中，“L”表示一个星期的最后一天，也就是SAT6L”表示这个月的倒数第６天，“FRIL”表示这个月的最一个星期五在使用“L”参数时，不要指定列表或范围，因为这会导致问题 例1：需要在每周五晚上三点钟执行 /root/dump.sh 脚本 例2：需要在每月10号执行 /root/dump.sh脚本 例3：在每月月底最后一天执行 /root/dump.sh脚本 cron的权限管理/etc/cron.deny文件为cron的黑名单，在此名单中的用户无法执行cron 另外/etc/cron.allow默认不存在，为白名单，若手动创建，则黑名单失效，除白名单外的用户无法执行cron at命令与周期性任务cron不同，at命令用于执行在某一时间只执行一次的一次性任务。 使用方法： at + 选项 + 时间参数 选项 常用的时间格式：&lt;时&gt;:&lt;分&gt; &lt;年&gt;-&lt;月&gt;-&lt;日&gt; &lt;时&gt;:&lt;分&gt; MMDDYY MM/DD/YY MM.DD.YY 英文月名 日期 年份 各种简写： Midnight(00:00) Noon(12:00) Teatime(16:00), now+time(从现在起的某段时间后执行) 例1:五分钟后执行a.sh 写法2： 权限控制同cron， 文件名/etc/at.deny、/etc/at.allow"},{"title":"kubernetes学习笔记(prometheus)","date":"2021-06-28T12:19:12.945Z","url":"/2021/06/28/kubernetes%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(prometheus)/","tags":[["kubernetes","/tags/kubernetes/"],["prometheus","/tags/prometheus/"]],"categories":[["kubernetes","/categories/kubernetes/"]],"content":"安装prometheusRBAC授权首先使用RBAC对prometheus进行授权: prometheus存储定义StorageClass存储（需要读写权限）: 配置文件我们把配置文件放在configMap中进行管理: 部署prometheus 注:这边要采用ingress的方式访问prometheus,也可通过其他方式访问: 方式二: 127.0.0.1:9090可以访问到prometheus 暴露prometheus服务 访问测试修改本地hosts为prometheus.k8s.local 访问此地址即可。 部署GrafanaGrafana是一个相对好用的数据展示工具，部署起来也比较简单 定义存储 部署Grafana 暴露服务 部署node-exporternode-exporter用于收集节点信息 使用在Grafana的dashboard中添加data source, 填入prometheus地址 ,这边是，刷新即可看到效果"},{"title":"通过例子学rust(迷你区块链)","date":"2021-06-24T15:37:53.922Z","url":"/2021/06/24/%E9%80%9A%E8%BF%87%E4%BE%8B%E5%AD%90%E5%AD%A6rust(%E8%BF%B7%E4%BD%A0%E5%8C%BA%E5%9D%97%E9%93%BE)/","tags":[["rust","/tags/rust/"]],"categories":[["rust","/categories/rust/"]],"content":"依旧来自 导入所需的包Cargo.toml 创建结构体(blockchain.rs)交易信息交易结构体需要包含发送者，接收者以及金额，同时需要实现序列化,Debug和Clone(后续创建新块需要)特性 区块头包含时间戳,前一个区块的hash,难度,默克尔值和nonce。 其中默克尔值是一个hash值，它包含每一笔交易的hash值。 nonce是用于工作量证明的值，得到一个nonce使得区块头的hash前X位为0，其中X为难度 区块体包含区块头，交易计数以及所有的交易信息 链包含区块列表当前交易，难度，矿工地址以及奖励 为链创建方法(blockchain.rs)创建新链要创建一个全新的区块链，我们需要得到第一笔交易信息，由Root发给第一位矿工。 首先新建一个链，接收矿工地址和难度两个参数，调用generate_new_block()方法生成第一个区块，最后返回一个chain实例 修改难度和奖励创建修改难度和奖励的方法 创建新的交易创建新交易很简单，只需要将发送者和接受者信息传入Transaction结构体，最后将结构体加入到链中的交易信息里即可，返回的bool用于判断是否创建成功。 计算当前块的hash值定义last_hash方法来计算当前块的hash值。 创建新的区块首先生成区块头，传入初始化信息。原视频使用time生成时间戳,这边使用了chrono。 然后产生一笔新的交易，从Root给miner。 创建一个新的区块，将此处的新交易添加到区块的交易中，并且将历史交易记录添加到此区块，此时transaction列表长度即为交易数。 通过get_merkle方法得到默克尔值，通过proof_of_work得到nonce，最后将此block打包到链中 计算默克尔值传入当前交易的列表，取出每一笔交易 计算hash后加入merkle列表。 如果默克尔列表中有奇数个值，则复制最后一个值并将其加入默克尔列表。 从默克尔hash列表中 取出前两个交易的hash值，拼接后将调用hash()得到一个hash，重复此操作直到默克尔列表中的hash被合并为一个时pop并返回。 工作量证明接收一个区块头并且计算hash，从hash中取出一定长度的切片并且将其解析，其中长度由difficulty决定。 parse::&lt;u32&gt;()会尝试将其解析为u32类型，这边得到的是一个Result类型，我们的目的是得到一个nonce使得最终区块头的hash值中，前X位都是0，所以在得到ERROR时，我们依然将nonce+1，知道得到所需的hash为止。 最后我们就得到了一个可以将区块头的hash的前X位变成0的nonce，用于证明工作。 hash计算hash接受一个可被serde序列化的结构体，将结构体变成字符串，我们调用sha2的方法输出得到一个&amp;[u8]类型的列表，通过hex_to_string 将其转换为一个16进制字符串，这边使用std::fmt::Write实现 主函数调用(main.rs)启动初始化启动此程序时，我们需要初始化数据，开始第一笔交易以创建区块链， 使用io::stdin().read_line读取用户输入，并且将参数传给blockchain::Chain::new创建全新的区块链 循环内容打印菜单，使用match匹配用户输入，对其做相应处理，通过对应函数返回的bool来判断执行结果 效果 完整代码 点击这里 blockchain.rs main.rs "},{"title":"kubernetes学习笔记(helm)","date":"2021-06-23T10:40:28.357Z","url":"/2021/06/23/helm%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/","tags":[["kubernetes","/tags/kubernetes/"],["helm","/tags/helm/"]],"categories":[["kubernetes","/categories/kubernetes/"]],"content":"安装helm我们可以使用以下命令安装helm 直接执行： 备注: 虽然存在包管理器安装，但官方并不建议使用 helm 基本功能1.创建新的 chart2.chart 打包成 tgz 格式3.上传 chart 到 chart 仓库或从仓库中下载 chart4.在Kubernetes集群中安装或卸载 chart5.管理用Helm安装的 chart 的发布周期 helm基本构成helm三大概念：Chart 代表着 Helm 包。它包含在 Kubernetes 集群内部运行应用程序，工具或服务所需的所有资源定义。你可以把它看作是 Homebrew formula，Apt dpkg，或 Yum RPM 在Kubernetes 中的等价物。 Repository（仓库）是用来存放和共享 charts 的地方。它就像 Perl 的CPAN 档案库网络或是 Fedora 的软件包仓库,只不过它是供 Kubernetes 包所使用的。 Release是运行在 Kubernetes集群中的 chart 的实例。一个chart通常可以在同一个集群中安装多次。每一次安装都会创建一个新的Release。以 MySQL chart为例，如果你想在你的集群中运行两个数据库，你可以安装该chart两次。每一个数据库都会拥有它自己的release和 release name。 在了解了上述这些概念以后，我们就可以这样来解释 Helm： Helm 安装charts到 Kubernetes 集群中，每次安装都会创建一个新的release。你可以在Helm的 chart repositories中寻找新的 chart。 helm安装chart示例以nginx为例：直接执行helm install安装 查看helm chart支持的参数 以下是完整内容 修改可配置选项在config.yaml 中自定义所需的选项 删除"},{"title":"kubernetes学习笔记(storage)","date":"2021-06-23T10:39:52.444Z","url":"/2021/06/23/k8s%20%E9%83%A8%E7%BD%B2%E8%AE%B0%E5%BD%95(3)%20pv&pvc&StorageClass/","tags":[["kubernetes","/tags/kubernetes/"],["pv","/tags/pv/"],["pvc","/tags/pvc/"],["storageclass","/tags/storageclass/"]],"categories":[["kubernetes","/categories/kubernetes/"]],"content":"存储相关概念pv： 持久化卷，可以使用ceph和nfs等pvc: 持久化卷声明,用于调度pv资源StorageClass： 定义存储类型，动态分配存储资源 环境准备首先建立一个nfs的server，此处不做多讲，kubernetes节点上也安装nfs服务 pv相关属性： pv相关属性包括了Capacity(存储能力)、AccessModes(访问模式)、ReclaimPolicy(回收策略)。 基本的capacity指标为storage=”存储容量”。访问模式包含以下三种：ReadWriteOnce（RWO）：读写权限，但是只能被单个节点挂载 ReadOnlyMany（ROX）：只读权限，可以被多个节点挂载 ReadWriteMany（RWX）：读写权限，可以被多个节点挂载 注: 不同的存储方式支持的访问模式不同，请参阅相关指南。回收策略： Retain（保留）- 保留数据，需要管理员手工清理数据 Recycle（回收）- 清除 PV 中的数据，效果相当于执行 rm -rf /yourdir/* Delete（删除）- 与 PV 相连的后端存储完成 volume 的删除操作 pv的状态通常有以下几种：Available（可用）：表示可用状态，还未被任何 PVC 绑定 Bound（已绑定）：表示 PV 已经被 PVC 绑定 Released（已释放）：PVC 被删除，但是资源还未被集群重新声明 Failed（失败）： 表示该 PV 的自动回收失败 pv实践接下来新建pv对象(pv1.yaml)： 应用: 创建pvc 注: pvc会自动寻找available状态的pv，无需额外声明。如果pv为2Gi，pvc为1Gi，同样会进行绑定，且pvc的容量会变成2Gi。 使用pvc作为服务的存储 nginx-service.yaml nginx-ingress.ymal StorageClass实践新建nfs-client的deployment 创建nfs-client的serviceaccount： 此处新建了一个serviceaccount同时绑定了一个clusterrole（用于声明权限） 创建sc对象 使用StorageClass 创建服务 "},{"title":"通过例子学rust(端口嗅探器)","date":"2021-06-19T06:48:35.994Z","url":"/2021/06/19/rust%E5%AD%A6%E4%B9%A0-%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E9%80%9A%E8%BF%87%E4%BE%8B%E5%AD%90%E5%AD%A6rust(%E7%AB%AF%E5%8F%A3%E5%97%85%E6%8E%A2%E5%99%A8)/","tags":[["rust","/tags/rust/"]],"categories":[["rust","/categories/rust/"]],"content":"简介个人推荐使用rust的clap库实现命令行程序功能 非原创,原版在这 搬运自 首先分析需求： 获取参数我们使用std::env 来获取用户输入的参数 测试一下得到的结果： 建立结构体我们用结构体来这些参数并且将其实例化 main函数中的错误处理让我们回到main函数 main中执行多线程扫描的部分 scan 函数 完整代码 完整代码 "},{"title":"rust学习笔记(泛型)","date":"2021-06-14T06:46:44.743Z","url":"/2021/06/14/rust%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E6%B3%9B%E5%9E%8B)/","tags":[["rust","/tags/rust/"]],"categories":[["rust","/categories/rust/"]],"content":"学习内容来自B站：原子之音 泛型结构体 结构体方法中的泛型 为泛型结构体中特定的类型实现方法 泛型方法 "},{"title":"kubernetes学习笔记（ingress）","date":"2021-06-09T10:34:58.207Z","url":"/2021/06/09/k8s%20%E9%83%A8%E7%BD%B2%E8%AE%B0%E5%BD%95%EF%BC%882%EF%BC%89%20ingress/","tags":[["kubernetes","/tags/kubernetes/"],["ingress","/tags/ingress/"]],"categories":[["kubernetes","/categories/kubernetes/"]],"content":"上次部署完成了k8s的基本框架，现在开始部署ingress，ingress其实就是从 kuberenets 集群外部访问集群的一个入口，将外部的请求转发到集群内不同的 Service 上，其实就相当于 nginx、haproxy 等负载均衡代理服务器。 创建traefik的crd资源 创建rbac.yaml 创建cokfigmap traefik 安装前准备在部署traefik之前 还需要安装Service APIs 安装api的两种方式 网络不佳的情况下 推荐下载下所有文件 创建deploy.yaml 文件 如果需要自定义标签的话 至此 traefik部署完成，如果需要访问traefik的dashboard 部署dashboard 修改本地hosts文件 访问 即可看到dashboard"},{"title":"kubernetes学习笔记（部署）","date":"2021-06-07T16:00:00.000Z","url":"/2021/06/08/k8s%20%20%E9%83%A8%E7%BD%B2%E8%AE%B0%E5%BD%95/","tags":[["kubernetes","/tags/kubernetes/"]],"categories":[["kubernetes","/categories/kubernetes/"]],"content":"准备三台干净的服务器，系统版本： CentOS Linux release 7.9.2009 添加hosts 配置docker加速 部署master节点 部署node节点 部署cni 容器网络 也可使用flannel 如果要切换cni插件，需要先把所有节点的/etc/cni/net.d/文件清空 验证kubernetes"},{"title":"Hello World","date":"2021-06-05T06:30:57.718Z","url":"/2021/06/05/firstblog/","tags":[["杂谈","/tags/%E6%9D%82%E8%B0%88/"]],"categories":[["杂谈","/categories/%E6%9D%82%E8%B0%88/"]],"content":"各种备忘的以及乱七八糟的东西都放到这从rust,python 的学习笔记到linux,docker 等有机会大概都会在这更新 做个纪录顺便防止自己哪天忘了 hexo主题来源为说明文档地址  "}]